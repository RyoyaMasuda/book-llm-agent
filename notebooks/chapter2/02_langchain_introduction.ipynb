{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv(\"/home/rmasuda/book-llm-agent/.env\")\n",
    "\n",
    "# OpenAI API キーの設定\n",
    "# api_key = getpass.getpass(\"OpenAI API キーを入力してください: \")\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2.2 チャットアプリ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# 1 モデルの定義\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "history = []\n",
    "n = 10\n",
    "for i in range(10):\n",
    "    user_input = input(\"ユーザ入力: \")\n",
    "    if user_input == \"exit\":\n",
    "        break\n",
    "    # 2 HumanMessage の作成と表示\n",
    "    human_message = HumanMessage(user_input)\n",
    "    human_message.pretty_print()\n",
    "    # 3 会話履歴の追加\n",
    "    history.append(HumanMessage(user_input))\n",
    "    # 4 応答の作成と表示\n",
    "    ai_message = llm.invoke(history)\n",
    "    ai_message.pretty_print()\n",
    "    # 5 会話履歴の追加\n",
    "    history.append(ai_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2.3 翻訳アプリ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "我思う、故に我あり\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# 1 テンプレートの作成\n",
    "TRANSLATION_PROMPT = \"\"\"\\\n",
    "以下の文章を {language} に翻訳し、翻訳結果のみを返してください。\n",
    "{source_text}\n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(TRANSLATION_PROMPT)\n",
    "\n",
    "# 2 Runnable の作成\n",
    "runnable = prompt | llm\n",
    "\n",
    "language = \"日本語\"\n",
    "source_text = \"\"\"\\\n",
    "cogito, ergo sum\n",
    "\"\"\"\n",
    "\n",
    "# 3 Runnable の実行と結果の表示\n",
    "response = runnable.invoke(dict(language=language, source_text=source_text))\n",
    "response.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2.4 テーブル作成アプリ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "import csv\n",
    "\n",
    "\n",
    "# 1 入力形式の定義\n",
    "class CSVSaveToolInput(BaseModel):\n",
    "    filename: str = Field(description=\"ファイル名\")\n",
    "    csv_text: str = Field(description=\"CSVのテキスト\")\n",
    "\n",
    "\n",
    "# 2 ツール本体の定義\n",
    "@tool(\"csv-save-tool\", args_schema=CSVSaveToolInput)\n",
    "def csv_save(filename: str, csv_text: str) -> bool:\n",
    "    \"\"\"CSV テキストをファイルに保存する\"\"\"\n",
    "    # parse CSV text\n",
    "    try:\n",
    "        rows = list(csv.reader(csv_text.splitlines()))\n",
    "    except Exception as e:\n",
    "        return False\n",
    "\n",
    "    # save to file\n",
    "    with open(filename, \"w\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(rows)\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fx: content='' additional_kwargs={'tool_calls': [{'id': 'call_VUfRLDtgzvmf4JOviPW5bKhE', 'function': {'arguments': '{\"filename\":\"fibonacci_sequence.csv\",\"csv_text\":\"番号,値\\\\n1,1\\\\n2,1\\\\n3,2\\\\n4,3\\\\n5,5\\\\n6,8\\\\n7,13\\\\n8,21\\\\n9,34\\\\n10,55\"}', 'name': 'csv-save-tool'}, 'type': 'function'}]} response_metadata={'token_usage': {'completion_tokens': 56, 'prompt_tokens': 129, 'total_tokens': 185, 'prompt_tokens_details': {'cached_tokens': 0, 'audio_tokens': 0}, 'completion_tokens_details': {'reasoning_tokens': 0, 'audio_tokens': 0, 'accepted_prediction_tokens': 0, 'rejected_prediction_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_129a36352a', 'finish_reason': 'stop', 'logprobs': None} id='run-802252da-4db4-4d55-97fc-4bff9d732c3d-0' tool_calls=[{'name': 'csv-save-tool', 'args': {'filename': 'fibonacci_sequence.csv', 'csv_text': '番号,値\\n1,1\\n2,1\\n3,2\\n4,3\\n5,5\\n6,8\\n7,13\\n8,21\\n9,34\\n10,55'}, 'id': 'call_VUfRLDtgzvmf4JOviPW5bKhE', 'type': 'tool_call'}] usage_metadata={'input_tokens': 129, 'output_tokens': 56, 'total_tokens': 185}\n",
      "x.tool_calls:[{'name': 'csv-save-tool', 'args': {'filename': 'fibonacci_sequence.csv', 'csv_text': '番号,値\\n1,1\\n2,1\\n3,2\\n4,3\\n5,5\\n6,8\\n7,13\\n8,21\\n9,34\\n10,55'}, 'id': 'call_VUfRLDtgzvmf4JOviPW5bKhE', 'type': 'tool_call'}]\n",
      "x.tool_calls[0]:{'name': 'csv-save-tool', 'args': {'filename': 'fibonacci_sequence.csv', 'csv_text': '番号,値\\n1,1\\n2,1\\n3,2\\n4,3\\n5,5\\n6,8\\n7,13\\n8,21\\n9,34\\n10,55'}, 'id': 'call_VUfRLDtgzvmf4JOviPW5bKhE', 'type': 'tool_call'}\n",
      "content='true' name='csv-save-tool' tool_call_id='call_VUfRLDtgzvmf4JOviPW5bKhE'\n"
     ]
    }
   ],
   "source": [
    "# 3 ツールを LLM に紐づける\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "tools = [csv_save]\n",
    "llm_with_tool = llm.bind_tools(tools=tools, tool_choice=\"csv-save-tool\")\n",
    "\n",
    "TABLE_PROMPT = \"\"\"\\\n",
    "{user_input}\n",
    "\n",
    "結果は CSV ファイルに保存してください。ただし、ファイル名は上記の内容から適切に決定してください。\n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(TABLE_PROMPT)\n",
    "# get_tool_args = lambda x: x.tool_calls[0]\n",
    "\n",
    "def get_tool_args(x):\n",
    "    print(f\"fx: {x}\")\n",
    "    print(f\"x.tool_calls:{x.tool_calls}\")\n",
    "    print(f\"x.tool_calls[0]:{x.tool_calls[0]}\")\n",
    "    return x.tool_calls[0] \n",
    "\n",
    "# 4 Runnable の作成\n",
    "runnable = prompt | llm_with_tool | get_tool_args | csv_save\n",
    "\n",
    "user_input = \"フィボナッチ数列の番号と値を10番目まで表にまとめて、CSV ファイルに保存してください。\"\n",
    "\n",
    "# 5 Runnable の実行と結果の確認\n",
    "response = runnable.invoke(dict(user_input=user_input))\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2.5 Plan-and-Solve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "# ツール入力形式の定義\n",
    "class ActionItem(BaseModel):\n",
    "    action_name: str = Field(description=\"アクション名\")\n",
    "    action_description: str = Field(description=\"アクションの詳細\")\n",
    "\n",
    "\n",
    "class Plan(BaseModel):\n",
    "    \"\"\"アクションプランを格納する\"\"\"\n",
    "\n",
    "    problem: str = Field(description=\"問題の説明\")\n",
    "    actions: list[ActionItem] = Field(description=\"実行すべきアクションリスト\")\n",
    "\n",
    "\n",
    "class ActionResult(BaseModel):\n",
    "    \"\"\"実行時の考えと結果を格納する\"\"\"\n",
    "\n",
    "    thoughts: str = Field(description=\"検討内容\")\n",
    "    result: str = Field(description=\"結果\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 単一アクションの実行\n",
    "from langchain_openai.output_parsers.tools import PydanticToolsParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "ACTION_PROMPT = \"\"\"\\\n",
    "問題をアクションプランに分解して解いています。\n",
    "これまでのアクションの結果と、次に行うべきアクションを示すので、実際にアクションを実行してその結果を報告してください。\n",
    "# 問題\n",
    "{problem}\n",
    "# アクションプラン\n",
    "{action_items}\n",
    "# これまでのアクションの結果\n",
    "{action_results}\n",
    "# 次のアクション\n",
    "{next_action}\n",
    "\"\"\"\n",
    "\n",
    "llm_action = llm.bind_tools([ActionResult], tool_choice=\"ActionResult\")\n",
    "action_parser = PydanticToolsParser(tools=[ActionResult], first_tool_only=True)\n",
    "plan_parser = PydanticToolsParser(tools=[Plan], first_tool_only=True)\n",
    "\n",
    "action_prompt = PromptTemplate.from_template(ACTION_PROMPT)\n",
    "action_runnable = action_prompt | llm_action | action_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# プランに含まれるアクションを実行するループ\n",
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "\n",
    "def action_loop(action_plan: Plan):\n",
    "    problem = action_plan.problem\n",
    "    actions = action_plan.actions\n",
    "\n",
    "    action_items = \"\\n\".join([\"* \" + action.action_name for action in actions])\n",
    "    action_results = []\n",
    "    action_results_str = \"\"\n",
    "    for i, action in enumerate(actions):\n",
    "        print(\"=\" * 20)\n",
    "        print(f\"[{i+1}/{len(actions)}]以下のアクションを実行します。\")\n",
    "        print(action.action_name)\n",
    "\n",
    "        next_action = f\"* {action.action_name}  \\n{action.action_description}\"\n",
    "        response = action_runnable.invoke(\n",
    "            dict(\n",
    "                problem=problem,\n",
    "                action_items=action_items,\n",
    "                action_results=action_results_str,\n",
    "                next_action=next_action,\n",
    "            )\n",
    "        )\n",
    "        action_results.append(response)\n",
    "        action_results_str += f\"* {action.action_name}  \\n{response.result}\\n\"\n",
    "        print(\"-\" * 10 + \"検討内容\" + \"-\" * 10)\n",
    "        print(response.thoughts)\n",
    "        print(\"-\" * 10 + \"結果\" + \"-\" * 10)\n",
    "        print(response.result)\n",
    "\n",
    "    return AIMessage(action_results_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plan-and-Solve を行うか否かの分岐\n",
    "def route(ai_message: AIMessage):\n",
    "    if ai_message.response_metadata[\"finish_reason\"] == \"tool_calls\":\n",
    "        return plan_parser | action_loop\n",
    "    else:\n",
    "        return ai_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全体を通した Runnable 作成\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "PLAN_AND_SOLVE_PROMPT = \"\"\"\\\n",
    "ユーザの質問が複雑な場合は、アクションプランを作成し、その後に1つずつ実行する Plan-and-Solve 形式をとります。\n",
    "これが必要と判断した場合は、Plan ツールによってアクションプランを保存してください。\n",
    "\"\"\"\n",
    "system_prompt = SystemMessage(PLAN_AND_SOLVE_PROMPT)\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [system_prompt, MessagesPlaceholder(variable_name=\"history\")]\n",
    ")\n",
    "\n",
    "llm_plan = llm.bind_tools(tools=[Plan])\n",
    "planning_runnable = chat_prompt | llm_plan | route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# チャット部分の作成\n",
    "history = []\n",
    "n = 10\n",
    "for i in range(10):\n",
    "    user_input = input(\"ユーザ入力: \")\n",
    "    if user_input == \"exit\":\n",
    "        break\n",
    "    # 1 HumanMessage の作成と表示\n",
    "    human_message = HumanMessage(user_input)\n",
    "    human_message.pretty_print()\n",
    "    # 2 会話履歴の追加\n",
    "    history.append(HumanMessage(user_input))\n",
    "    # 3 応答の作成と表示\n",
    "    ai_message = planning_runnable.invoke(dict(history=history))\n",
    "    ai_message.pretty_print()\n",
    "    # 4 会話履歴の追加\n",
    "    history.append(ai_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 出力例\n",
    "\n",
    "# ================================ Human Message =================================\n",
    "#\n",
    "# ある製造工場では、1時間に200個の部品が生産されます。工場は1日8時間稼働し、1週間に5日間営業しています。生産された部品のうち5%は品質不良で廃棄されます。この工場では1ヶ月（4週間）に品質不良で廃棄される部品の総数を求めなさい。\n",
    "# ====================\n",
    "# [1/4]以下のアクションを実行します。\n",
    "# 部品の1日の生産量を求める\n",
    "# ----------検討内容----------\n",
    "# 部品の1日の生産量を求めた結果、1日の生産量は1600個である。\n",
    "# ----------結果----------\n",
    "# 部品の1日の生産量は1600個である。\n",
    "# ====================\n",
    "# [2/4]以下のアクションを実行します。\n",
    "# 部品の1週間の生産量を求める\n",
    "# ----------検討内容----------\n",
    "# 1週間の生産量を求めた。1日の生産量1600個に5営業日を掛けて計算した結果、8000個となった。この結果を記録する。\n",
    "# ----------結果----------\n",
    "# 部品の1週間の生産量は8000個である。\n",
    "# ====================\n",
    "# [3/4]以下のアクションを実行します。\n",
    "# 部品の1ヶ月の生産量を求める\n",
    "# ----------検討内容----------\n",
    "# 部品の1ヶ月の生産量は8000個 × 4週間 = 32000個と計算した。\n",
    "# ----------結果----------\n",
    "# 部品の1ヶ月の生産量は32000個である。\n",
    "# ====================\n",
    "# [4/4]以下のアクションを実行します。\n",
    "# 品質不良で廃棄される部品の数を求める\n",
    "# ----------検討内容----------\n",
    "# 品質不良で廃棄される部品の数を求めるために、1ヶ月の生産量32000個に5%を掛け算して1600個を算出する。\n",
    "# ----------結果----------\n",
    "# 品質不良で廃棄される部品の数は1600個である。\n",
    "# ================================== Ai Message ==================================\n",
    "#\n",
    "# * 部品の1日の生産量を求める\n",
    "# 部品の1日の生産量は1600個である。\n",
    "# * 部品の1週間の生産量を求める\n",
    "# 部品の1週間の生産量は8000個である。\n",
    "# * 部品の1ヶ月の生産量を求める\n",
    "# 部品の1ヶ月の生産量は32000個である。\n",
    "# * 品質不良で廃棄される部品の数を求める\n",
    "# 品質不良で廃棄される部品の数は1600個である。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm-agent-U4qSWGiP-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
