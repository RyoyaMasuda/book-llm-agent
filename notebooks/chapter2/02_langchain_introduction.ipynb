{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2.2 チャットアプリ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "load_dotenv(\"../.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 モデルの定義\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "history = []\n",
    "n = 10\n",
    "for i in range(10):\n",
    "    user_input = input(\"ユーザ入力: \")\n",
    "    if user_input == \"exit\":\n",
    "        break\n",
    "    #2 HumanMessage の作成と表示\n",
    "    human_message = HumanMessage(user_input)\n",
    "    human_message.pretty_print()\n",
    "    #3 会話履歴の追加\n",
    "    history.append(HumanMessage(user_input))\n",
    "    #4 応答の作成と表示\n",
    "    ai_message = llm.invoke(history)\n",
    "    ai_message.pretty_print()\n",
    "    #5 会話履歴の追加\n",
    "    history.append(ai_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2.3 翻訳アプリ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "load_dotenv(\"../.env\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "#1 プロンプトテンプレートの作成\n",
    "TRANSLATION_PROMPT = \"\"\"\\\n",
    "以下の文章を {language} に翻訳し、翻訳結果のみを返してください。\n",
    "{source_text}\n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(TRANSLATION_PROMPT)\n",
    "\n",
    "#2 Runnable の作成\n",
    "runnable = prompt | llm\n",
    "\n",
    "language = \"日本語\"\n",
    "source_text = \"\"\"\\\n",
    "cogito, ergo sum\n",
    "\"\"\"\n",
    "\n",
    "#3 Runnable の実行と結果の表示\n",
    "response = runnable.invoke(dict(language=language, source_text=source_text))\n",
    "response.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2.4 テーブル作成アプリ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool\n",
    "from langchain.pydantic_v1 import BaseModel, Field\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "import csv\n",
    "\n",
    "#1 入力の定義\n",
    "class CSVSaveToolInput(BaseModel):\n",
    "    filename: str = Field(description=\"ファイル名\")\n",
    "    csv_text: str = Field(description=\"CSVのテキスト\")\n",
    "\n",
    "#2 ツールの定義\n",
    "@tool(\"csv-save-tool\", args_schema=CSVSaveToolInput)\n",
    "def csv_save(filename: str, csv_text: str) -> bool:\n",
    "    \"\"\"CSV テキストをファイルに保存する\"\"\"\n",
    "    # parse CSV text\n",
    "    try:\n",
    "        rows = list(csv.reader(csv_text.splitlines()))\n",
    "    except Exception as e:\n",
    "        return False\n",
    "\n",
    "    # save to file\n",
    "    with open(filename, \"w\") as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerows(rows)\n",
    "\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1 ツールを LLM に紐づける\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "tools = [csv_save]\n",
    "llm_with_tool = llm.bind_tools(tools=tools)\n",
    "\n",
    "TABLE_PROMPT = \"\"\"\\\n",
    "{user_input}\n",
    "\n",
    "結果は CSV ファイルに保存してください。ただし、ファイル名は上記の内容から適切に決定してください。\n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(TABLE_PROMPT)\n",
    "get_tool_args = lambda x: x.tool_calls[0][\"args\"]\n",
    "\n",
    "#2 Runnable の作成\n",
    "runnable = prompt | llm_with_tool | get_tool_args | csv_save\n",
    "\n",
    "user_input = \"フィボナッチ数列の番号と値を10番目まで表にまとめて、CSV ファイルに保存してください。\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = runnable.invoke(dict(user_input=user_input))\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plan-and-Solve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"../.env\")\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActionItem(BaseModel):\n",
    "    action_name: str = Field(description=\"アクション名\")\n",
    "    action_description: str = Field(description=\"アクションの詳細\")\n",
    "\n",
    "\n",
    "class Plan(BaseModel):\n",
    "    \"\"\"アクションプランを格納する\"\"\"\n",
    "    problem: str = Field(description=\"問題の説明\")\n",
    "    actions: list[ActionItem] = Field(description=\"実行すべきアクションリスト\")\n",
    "\n",
    "\n",
    "class ActionResult(BaseModel):\n",
    "    \"\"\"実行時の考えと結果を格納する\"\"\"\n",
    "\n",
    "    thoughts: str = Field(description=\"検討内容\")\n",
    "    result: str = Field(description=\"結果\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers.openai_tools import PydanticToolsParser\n",
    "\n",
    "ACTION_PROMPT = \"\"\"\\\n",
    "問題をアクションプランに分解して解いています。\n",
    "これまでのアクションの結果と、次に行うべきアクションを示すので、最新のアクションに関する情報のみを返してください。\n",
    "# 問題\n",
    "{problem}\n",
    "# アクションプラン\n",
    "{action_items}\n",
    "# これまでのアクションの結果\n",
    "{action_results}\n",
    "# 次のアクション\n",
    "{next_action}\n",
    "\"\"\"\n",
    "\n",
    "llm_action = llm.bind_tools([ActionResult], tool_choice=\"ActionResult\")\n",
    "action_parser = PydanticToolsParser(tools=[ActionResult], first_tool_only=True)\n",
    "plan_parser = PydanticToolsParser(tools=[Plan], first_tool_only=True)\n",
    "\n",
    "action_prompt = PromptTemplate.from_template(ACTION_PROMPT)\n",
    "action_runnable = action_prompt | llm_action | action_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "\n",
    "def action_loop(action_plan: Plan):\n",
    "    problem = action_plan.problem\n",
    "    actions = action_plan.actions\n",
    "\n",
    "    action_items = \"\\n\".join([\"* \" + action.action_name for action in actions])\n",
    "    action_results = []\n",
    "    action_results_str = \"\"\n",
    "    for i, action in enumerate(actions):\n",
    "        print(\"=\"*20)\n",
    "        print(f\"[{i+1}/{len(actions)}]以下のアクションを実行します。\")\n",
    "        print(action.action_name)\n",
    "\n",
    "        next_action = f\"* {action.action_name}  \\n{action.action_description}\"\n",
    "        response = action_runnable.invoke(dict(problem=problem, action_items=action_items, action_results=action_results_str, next_action=next_action))\n",
    "        action_results.append(response)\n",
    "        action_results_str += f\"* {action.action_name}  \\n{response.result}\\n\" \n",
    "        print(\"-\" *10 + \"検討内容\" + \"-\"*10)\n",
    "        print(response.thoughts)\n",
    "        print(\"-\" *10 + \"結果\" + \"-\" * 10)\n",
    "        print(response.result)\n",
    "\n",
    "    return AIMessage(action_results_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def route(ai_message: AIMessage):\n",
    "    if ai_message.response_metadata[\"finish_reason\"] == \"tool_calls\":\n",
    "        return plan_parser | RunnableLambda(action_loop)\n",
    "    else:\n",
    "        return ai_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "PLAN_AND_SOLVE_PROMPT = f\"\"\"\\\n",
    "ユーザの質問が複雑な場合は、アクションプランを作成し、その後に1つずつ実行する Plan-and-Solve 形式をとります。\n",
    "これが必要と判断した場合は、Plan ツールによってアクションプランを保存してください。\n",
    "\"\"\"\n",
    "system_prompt = SystemMessage(PLAN_AND_SOLVE_PROMPT)\n",
    "chat_prompt = ChatPromptTemplate.from_messages([system_prompt, MessagesPlaceholder(variable_name=\"history\")])\n",
    "\n",
    "llm_plan = llm.bind_tools(tools=[Plan])\n",
    "planning_runnable = chat_prompt | llm_plan | route"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "こんにちは\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "こんにちは！今日はどのようなことをお手伝いできますか？\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "f(x) = x^2 + x + 1 の極値を計算して\n",
      "====================\n",
      "[1/3]以下のアクションを実行します。\n",
      "関数の導関数を求める\n",
      "----------検討内容----------\n",
      "関数 f(x) = x^2 + x + 1 の導関数 f'(x) を求めるためには、微分を行う必要がある。微分を行うと、f'(x) = 2x + 1 となる。\n",
      "----------結果----------\n",
      "f'(x) = 2x + 1\n",
      "====================\n",
      "[2/3]以下のアクションを実行します。\n",
      "導関数をゼロに設定する\n",
      "----------検討内容----------\n",
      "導関数 f'(x) = 2x + 1 をゼロに設定し、x の値を求めることで、極値の候補を見つける。\n",
      "----------結果----------\n",
      "2x + 1 = 0 から x = -1/2 が得られた。\n",
      "====================\n",
      "[3/3]以下のアクションを実行します。\n",
      "極値を計算する\n",
      "----------検討内容----------\n",
      "得られた x の値 x = -1/2 を f(x) に代入して、極値を計算する。具体的には、f(-1/2) を求める。\n",
      "----------結果----------\n",
      "f(-1/2) = (-1/2)^2 + (-1/2) + 1 = 1/4 - 1/2 + 1 = 1/4 - 2/4 + 4/4 = 3/4 よって、極値は 3/4 である。\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "* 関数の導関数を求める  \n",
      "f'(x) = 2x + 1* 導関数をゼロに設定する  \n",
      "2x + 1 = 0 から x = -1/2 が得られた。* 極値を計算する  \n",
      "f(-1/2) = (-1/2)^2 + (-1/2) + 1 = 1/4 - 1/2 + 1 = 1/4 - 2/4 + 4/4 = 3/4 よって、極値は 3/4 である。\n"
     ]
    }
   ],
   "source": [
    "history = []\n",
    "n = 10\n",
    "for i in range(10):\n",
    "    user_input = input(\"ユーザ入力: \")\n",
    "    if user_input == \"exit\":\n",
    "        break\n",
    "    #2 HumanMessage の作成と表示\n",
    "    human_message = HumanMessage(user_input)\n",
    "    human_message.pretty_print()\n",
    "    #3 会話履歴の追加\n",
    "    history.append(HumanMessage(user_input))\n",
    "    #4 応答の作成と表示\n",
    "    ai_message = planning_runnable.invoke(dict(history=history))\n",
    "    ai_message.pretty_print()\n",
    "    #5 会話履歴の追加\n",
    "    history.append(ai_message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
