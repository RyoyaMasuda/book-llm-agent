{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 準備"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "import gradio as gr\n",
    "\n",
    "# OpenAI API キーの設定\n",
    "api_key = getpass.getpass(\"OpenAI API キーを入力してください: \")\n",
    "os.environ[\"OPENAI_API_KEY\"] = api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradio の基礎"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 簡単なインターフェースの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2text(text):\n",
    "    text = \"<<\" + text + \">>\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = gr.Text(label=\"入力\")\n",
    "output_text = gr.Text(label=\"出力\")\n",
    "\n",
    "demo = gr.Interface(inputs=input_text, outputs=output_text, fn=text2text)\n",
    "demo.launch(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ブロックの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2text_rich(text):\n",
    "    top = \"^\" * len(text)\n",
    "    bottom = \"v\" * len(text)\n",
    "    text = f\" {top}\\n<{text}>\\n {bottom}\"\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    input_text = gr.Text(label=\"入力\")\n",
    "    button1 = gr.Button(value=\"Normal\")\n",
    "    button2 = gr.Button(value=\"Rich\")\n",
    "    output_text = gr.Text(label=\"出力\")\n",
    "\n",
    "    button1.click(inputs=input_text, outputs=output_text, fn=text2text)\n",
    "    button2.click(inputs=input_text, outputs=output_text, fn=text2text_rich)\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 重要なコンポーネント"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_upload(audio):\n",
    "    return audio\n",
    "\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    # Audio\n",
    "    audio = gr.Audio(label=\"音声\", type=\"filepath\")\n",
    "    # Checkbox\n",
    "    checkbox = gr.Checkbox(label=\"チェックボックス\")\n",
    "    # File\n",
    "    file = gr.File(label=\"ファイル\", file_types=[\"image\"])\n",
    "    # Number\n",
    "    number = gr.Number(label=\"数値\")\n",
    "    # Markdown\n",
    "    markdown = gr.Markdown(label=\"Markdown\", value=\"# タイトル\\n## サブタイトル\\n本文\")\n",
    "    # Slider\n",
    "    slider = gr.Slider(\n",
    "        label=\"スライダー\", minimum=-10, maximum=10, step=0.5, interactive=True\n",
    "    )\n",
    "    # Textbox\n",
    "    textbox = gr.Textbox(label=\"テキストボックス\")\n",
    "\n",
    "demo.launch(height=1200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UI の工夫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    # Accordion\n",
    "    with gr.Accordion(label=\"アコーディオン\"):\n",
    "        gr.Text(value=\"アコーディオンの中身\")\n",
    "    with gr.Row():\n",
    "        gr.Text(value=\"左\")\n",
    "        gr.Text(value=\"右\")\n",
    "\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            gr.Text(value=\"(0, 0)\")\n",
    "            gr.Text(value=\"(1, 0)\")\n",
    "        with gr.Column():\n",
    "            gr.Text(value=\"(0, 1)\")\n",
    "            gr.Text(value=\"(1, 1)\")\n",
    "\n",
    "    with gr.Tab(label=\"タブ1\"):\n",
    "        gr.Text(value=\"コンテンツ1\")\n",
    "    with gr.Tab(label=\"タブ2\"):\n",
    "        gr.Text(value=\"コンテンツ2\")\n",
    "\n",
    "demo.launch(height=800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    slider = gr.Slider(label=\"個数\", minimum=0, maximum=10, step=1)\n",
    "\n",
    "    @gr.render(inputs=slider)\n",
    "    def render_blocks(value):\n",
    "        for i in range(value):\n",
    "            gr.Text(value=f\"Block {i}\")\n",
    "\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "def iterative_output():\n",
    "    for i in range(10):\n",
    "        time.sleep(0.5)\n",
    "        yield str(i)\n",
    "\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    button = gr.Button(\"実行\")\n",
    "    output = gr.Text(label=\"出力\")\n",
    "    button.click(outputs=output, fn=iterative_output)\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 状態を保持する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    username = gr.State(\"\")\n",
    "    text_input = gr.Text(label=\"ユーザ名\")\n",
    "    button1 = gr.Button(\"決定\")\n",
    "    button2 = gr.Button(\"自分の名前を表示\")\n",
    "    text_output = gr.Text(label=\"出力\")\n",
    "    button1.click(inputs=text_input, outputs=username, fn=lambda x: x)\n",
    "    button2.click(inputs=username, outputs=text_output, fn=lambda x: x)\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## チャット UI を作る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "\n",
    "def history2messages(history):\n",
    "    messages = []\n",
    "    for user, assistant in history:\n",
    "        messages.append({\"role\": \"user\", \"content\": user})\n",
    "        messages.append({\"role\": \"assistant\", \"content\": assistant})\n",
    "    return messages\n",
    "\n",
    "\n",
    "def chat(message, history):\n",
    "    messages = history2messages(history)\n",
    "    messages.append({\"role\": \"user\", \"content\": message})\n",
    "    response = llm.invoke(message)\n",
    "    return response.content\n",
    "\n",
    "\n",
    "demo = gr.ChatInterface(chat)\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stream チャットボット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "\n",
    "def chat(message, history):\n",
    "    messages = history2messages(history)\n",
    "    messages.append({\"role\": \"user\", \"content\": message})\n",
    "    output = \"\"\n",
    "    for chunk in llm.stream(messages):\n",
    "        output += chunk.content\n",
    "        yield output\n",
    "\n",
    "\n",
    "demo = gr.ChatInterface(chat)\n",
    "\n",
    "demo.launch(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradio の応用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 翻訳アプリケーション"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2.3 の Runnable\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# 1 テンプレートの作成\n",
    "TRANSLATION_PROMPT = \"\"\"\\\n",
    "以下の文章を {language} に翻訳し、翻訳結果のみを返してください。\n",
    "{source_text}\n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(TRANSLATION_PROMPT)\n",
    "\n",
    "# 2 Runnable の作成\n",
    "runnable = prompt | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = [\"日本語\", \"英語\", \"中国語\", \"ラテン語\", \"ギリシャ語\"]\n",
    "\n",
    "\n",
    "def translate(source_text, language):\n",
    "    # 3 Runnable の実行\n",
    "    response = runnable.invoke(dict(source_text=source_text, language=language))\n",
    "    return response.content\n",
    "\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    # 入力テキスト\n",
    "    source_text = gr.Textbox(label=\"翻訳元の文章\")\n",
    "    # 言語を選択\n",
    "    language = gr.Dropdown(label=\"言語\", choices=languages)\n",
    "    button = gr.Button(\"翻訳\")\n",
    "    # 出力テキスト\n",
    "    translated_text = gr.Textbox(label=\"翻訳結果\")\n",
    "\n",
    "    button.click(inputs=[source_text, language], outputs=translated_text, fn=translate)\n",
    "\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## テーブル作成アプリケーション"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2.4 の Runnable\n",
    "import csv\n",
    "\n",
    "import pandas as pd\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "\n",
    "# 1 入力形式の定義\n",
    "class CSV2DFToolInput(BaseModel):\n",
    "    csv_text: str = Field(description=\"CSVのテキスト\")\n",
    "\n",
    "\n",
    "# 2 ツール本体の定義. csv を保存するツールから json に変換するツールに変更\n",
    "@tool(\"csv2json-tool\", args_schema=CSV2DFToolInput, return_direct=True)\n",
    "def csv2json(csv_text: str) -> pd.DataFrame:\n",
    "    \"\"\"CSV テキストを pandas DataFrame に変換する\"\"\"\n",
    "    try:\n",
    "        rows = list(csv.reader(csv_text.splitlines()))\n",
    "        df = pd.DataFrame(rows[1:], columns=rows[0])\n",
    "    except Exception:\n",
    "        df = pd.DataFrame()\n",
    "    return df.to_json()\n",
    "\n",
    "\n",
    "# 3 ツールを LLM に紐づける\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "# bind するツールを変更\n",
    "tools = [csv2json]\n",
    "llm_with_tool = llm.bind_tools(tools=tools, tool_choice=\"csv2json-tool\")\n",
    "\n",
    "# プロンプトを修正\n",
    "TABLE_PROMPT = \"\"\"\\\n",
    "{user_input}\n",
    "結果は CSV で作成し、csv2json-tool を利用して json に変換してください。\n",
    "\"\"\"\n",
    "prompt = PromptTemplate.from_template(TABLE_PROMPT)\n",
    "\n",
    "\n",
    "# 4 Runnable の作成\n",
    "def get_tool_args(x):\n",
    "    return x.tool_calls[0]  # AIMessage から ToolCall オブジェクトを取り出す。\n",
    "\n",
    "\n",
    "runnable = prompt | llm_with_tool | get_tool_args | csv2json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df(user_input):\n",
    "    response = runnable.invoke(dict(user_input=user_input))\n",
    "    json_str = response.content\n",
    "    df = pd.read_json(json_str)\n",
    "    return df\n",
    "\n",
    "\n",
    "with gr.Blocks() as demo:\n",
    "    # 入力テキスト\n",
    "    user_input = gr.Textbox(label=\"テーブルを作成したい内容のテキスト\")\n",
    "    button = gr.Button(\"実行\")\n",
    "    # 出力テキスト\n",
    "    output_table = gr.DataFrame()\n",
    "\n",
    "    button.click(inputs=user_input, outputs=output_table, fn=create_df)\n",
    "\n",
    "demo.launch(height=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plan-and-Solve チャットボット"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "\n",
    "\n",
    "# ツール入力形式の定義\n",
    "class ActionItem(BaseModel):\n",
    "    action_name: str = Field(description=\"アクション名\")\n",
    "    action_description: str = Field(description=\"アクションの詳細\")\n",
    "\n",
    "\n",
    "class Plan(BaseModel):\n",
    "    \"\"\"アクションプランを格納する\"\"\"\n",
    "\n",
    "    problem: str = Field(description=\"問題の説明\")\n",
    "    actions: list[ActionItem] = Field(description=\"実行すべきアクションリスト\")\n",
    "\n",
    "\n",
    "class ActionResult(BaseModel):\n",
    "    \"\"\"実行時の考えと結果を格納する\"\"\"\n",
    "\n",
    "    thoughts: str = Field(description=\"検討内容\")\n",
    "    result: str = Field(description=\"結果\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 単一アクションの実行\n",
    "from langchain_openai.output_parsers.tools import PydanticToolsParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "ACTION_PROMPT = \"\"\"\\\n",
    "問題をアクションプランに分解して解いています。\n",
    "これまでのアクションの結果と、次に行うべきアクションを示すので、実際にアクションを実行してその結果を報告してください。\n",
    "# 問題\n",
    "{problem}\n",
    "# アクションプラン\n",
    "{action_items}\n",
    "# これまでのアクションの結果\n",
    "{action_results}\n",
    "# 次のアクション\n",
    "{next_action}\n",
    "\"\"\"\n",
    "\n",
    "llm_action = llm.bind_tools([ActionResult], tool_choice=\"ActionResult\")\n",
    "action_parser = PydanticToolsParser(tools=[ActionResult], first_tool_only=True)\n",
    "plan_parser = PydanticToolsParser(tools=[Plan], first_tool_only=True)\n",
    "\n",
    "action_prompt = PromptTemplate.from_template(ACTION_PROMPT)\n",
    "action_runnable = action_prompt | llm_action | action_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# プランに含まれるアクションを実行するループ\n",
    "def action_loop(action_plan: Plan):\n",
    "    problem = action_plan.problem\n",
    "    actions = action_plan.actions\n",
    "\n",
    "    action_items = \"\\n\".join([\"* \" + action.action_name for action in actions])\n",
    "    action_results = []\n",
    "    action_results_str = \"\"\n",
    "    for _, action in enumerate(actions):\n",
    "        next_action = f\"* {action.action_name}  \\n{action.action_description}\"\n",
    "        response = action_runnable.invoke(\n",
    "            dict(\n",
    "                problem=problem,\n",
    "                action_items=action_items,\n",
    "                action_results=action_results_str,\n",
    "                next_action=next_action,\n",
    "            )\n",
    "        )\n",
    "        action_results.append(response)\n",
    "        action_results_str += f\"* {action.action_name}  \\n{response.result}\\n\"\n",
    "        yield (\n",
    "            response.thoughts,\n",
    "            response.result,\n",
    "        )  # 変更ポイント: 途中結果を yield で返す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 全体を通した Runnable 作成\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "PLAN_AND_SOLVE_PROMPT = \"\"\"\\\n",
    "ユーザの質問が複雑な場合は、アクションプランを作成し、その後に1つずつ実行する Plan-and-Solve 形式をとります。\n",
    "これが必要と判断した場合は、Plan ツールによってアクションプランを保存してください。\n",
    "\"\"\"\n",
    "system_prompt = SystemMessage(PLAN_AND_SOLVE_PROMPT)\n",
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [system_prompt, MessagesPlaceholder(variable_name=\"history\")]\n",
    ")\n",
    "\n",
    "llm_plan = llm.bind_tools(tools=[Plan])\n",
    "planning_runnable = chat_prompt | llm_plan  # route を削除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gradio import ChatMessage\n",
    "from langchain_core.messages import AIMessage, HumanMessage\n",
    "\n",
    "\n",
    "def chat(prompt, messages, history):\n",
    "    # 描画用の履歴をアップデート\n",
    "    messages.append(ChatMessage(role=\"user\", content=prompt))\n",
    "    # LangChain 用の履歴をアップデート\n",
    "    history.append(HumanMessage(content=prompt))\n",
    "    # プランまたは返答を作成\n",
    "    response = planning_runnable.invoke(dict(history=history))\n",
    "    if response.response_metadata[\"finish_reason\"] != \"tool_calls\":\n",
    "        # タスクが簡単な場合はプランを作らずに返す\n",
    "        messages.append(ChatMessage(role=\"assistant\", content=response.content))\n",
    "        history.append(AIMessage(content=response.content))\n",
    "        yield \"\", messages, history\n",
    "    else:\n",
    "        # アクションプランを抽出\n",
    "        action_plan = plan_parser.invoke(response)\n",
    "\n",
    "        # アクション名を表示\n",
    "        action_items = \"\\n\".join(\n",
    "            [\"* \" + action.action_name for action in action_plan.actions]\n",
    "        )\n",
    "        messages.append(\n",
    "            ChatMessage(\n",
    "                role=\"assistant\",\n",
    "                content=action_items,\n",
    "                metadata={\"title\": \"実行されるアクション\"},\n",
    "            )\n",
    "        )\n",
    "        # プランの段階で一度描画する\n",
    "        yield \"\", messages, history\n",
    "\n",
    "        # アクションプランを実行\n",
    "        action_results_str = \"\"\n",
    "        for i, (thoughts, result) in enumerate(action_loop(action_plan)):\n",
    "            action_name = action_plan.actions[i].action_name\n",
    "            action_results_str += f\"* {action_name}  \\n{result}\\n\"\n",
    "            text = f\"## {action_name}\\n### 思考過程\\n{thoughts}\\n### 結果\\n{result}\"\n",
    "            messages.append(ChatMessage(role=\"assistant\", content=text))\n",
    "            # 実行結果を描画する\n",
    "            yield \"\", messages, history\n",
    "\n",
    "        history.append(AIMessage(content=action_results_str))\n",
    "        # LangChain 用の履歴を更新する\n",
    "        yield \"\", messages, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gr.Blocks() as demo:\n",
    "    chatbot = gr.Chatbot(label=\"Assistant\", type=\"messages\", height=800)\n",
    "    history = gr.State([])\n",
    "    with gr.Row():\n",
    "        with gr.Column(scale=9):\n",
    "            user_input = gr.Textbox(lines=1, label=\"Chat Message\")\n",
    "        with gr.Column(scale=1):\n",
    "            submit = gr.Button(\"Submit\")\n",
    "            clear = gr.ClearButton([user_input, chatbot, history])\n",
    "    submit.click(\n",
    "        chat,\n",
    "        inputs=[user_input, chatbot, history],\n",
    "        outputs=[user_input, chatbot, history],\n",
    "    )\n",
    "demo.launch(height=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
